{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dadf3e39-7718-4fd0-a4ca-f04af2ee8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "043c32c1-f7ca-4267-872e-b188faee15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerLookalikeModel:\n",
    "    def __init__(self):\n",
    "        # Initialize model components\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_matrix = None\n",
    "        self.customer_ids = None\n",
    "        self.features = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess all required data\"\"\"\n",
    "        # Load datasets\n",
    "        self.customers_df = pd.read_csv('Customers.csv')\n",
    "        self.products_df = pd.read_csv('Products.csv')\n",
    "        self.transactions_df = pd.read_csv('Transactions.csv')\n",
    "        \n",
    "        # Convert dates\n",
    "        self.customers_df['SignupDate'] = pd.to_datetime(self.customers_df['SignupDate'])\n",
    "        self.transactions_df['TransactionDate'] = pd.to_datetime(self.transactions_df['TransactionDate'])\n",
    "    \n",
    "    def create_customer_features(self):\n",
    "        \"\"\"Create comprehensive customer features from all available data\"\"\"\n",
    "        # Basic customer features\n",
    "        customer_features = self.customers_df.copy()\n",
    "        \n",
    "        # Transaction-based features\n",
    "        transaction_features = self.transactions_df.groupby('CustomerID').agg({\n",
    "            'TransactionID': 'count',\n",
    "            'TotalValue': ['sum', 'mean', 'std'],\n",
    "            'Quantity': ['sum', 'mean', 'std'],\n",
    "            'TransactionDate': ['min', 'max']\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Flatten column names\n",
    "        transaction_features.columns = [\n",
    "            'CustomerID', 'total_transactions', \n",
    "            'total_spend', 'avg_transaction_value', 'std_transaction_value',\n",
    "            'total_items', 'avg_items_per_transaction', 'std_items_per_transaction',\n",
    "            'first_purchase_date', 'last_purchase_date'\n",
    "        ]\n",
    "        \n",
    "        # Calculate customer lifetime\n",
    "        transaction_features['first_purchase_date'] = pd.to_datetime(transaction_features['first_purchase_date'])\n",
    "        transaction_features['last_purchase_date'] = pd.to_datetime(transaction_features['last_purchase_date'])\n",
    "        transaction_features['customer_lifetime_days'] = (\n",
    "            transaction_features['last_purchase_date'] - transaction_features['first_purchase_date']\n",
    "        ).dt.days\n",
    "        \n",
    "        # Category preferences\n",
    "        category_preferences = (\n",
    "            self.transactions_df\n",
    "            .merge(self.products_df[['ProductID', 'Category']], on='ProductID')\n",
    "            .groupby(['CustomerID', 'Category'])\n",
    "            .agg({'TransactionID': 'count'})\n",
    "            .reset_index()\n",
    "            .pivot(index='CustomerID', columns='Category', values='TransactionID')\n",
    "            .fillna(0)\n",
    "        )\n",
    "        category_preferences.columns = [f'purchases_{col.lower()}' for col in category_preferences.columns]\n",
    "        \n",
    "        # Price tier preferences\n",
    "        self.products_df['price_tier'] = pd.qcut(self.products_df['Price'], q=3, labels=['low', 'medium', 'high'])\n",
    "        price_preferences = (\n",
    "            self.transactions_df\n",
    "            .merge(self.products_df[['ProductID', 'price_tier']], on='ProductID')\n",
    "            .groupby(['CustomerID', 'price_tier'])\n",
    "            .agg({'TransactionID': 'count'})\n",
    "            .reset_index()\n",
    "            .pivot(index='CustomerID', columns='price_tier', values='TransactionID')\n",
    "            .fillna(0)\n",
    "        )\n",
    "        price_preferences.columns = [f'price_tier_{col}' for col in price_preferences.columns]\n",
    "        \n",
    "        # Merge all features\n",
    "        self.features = (\n",
    "            customer_features\n",
    "            .merge(transaction_features, on='CustomerID', how='left')\n",
    "            .merge(category_preferences, on='CustomerID', how='left')\n",
    "            .merge(price_preferences, on='CustomerID', how='left')\n",
    "        )\n",
    "        \n",
    "        # Fill NaN values\n",
    "        self.features = self.features.fillna(0)\n",
    "        \n",
    "        return self.features\n",
    "    \n",
    "    def prepare_feature_matrix(self):\n",
    "        \"\"\"Prepare the final feature matrix for similarity calculation\"\"\"\n",
    "        # Select and prepare features for similarity calculation\n",
    "        numerical_features = [\n",
    "            'total_transactions', 'total_spend', 'avg_transaction_value', \n",
    "            'std_transaction_value', 'total_items', 'avg_items_per_transaction',\n",
    "            'std_items_per_transaction', 'customer_lifetime_days'\n",
    "        ] + [col for col in self.features.columns if col.startswith(('purchases_', 'price_tier_'))]\n",
    "        \n",
    "        # Store customer IDs\n",
    "        self.customer_ids = self.features['CustomerID'].values\n",
    "        \n",
    "        # Create and scale feature matrix\n",
    "        feature_matrix = self.features[numerical_features].copy()\n",
    "        self.feature_matrix = self.scaler.fit_transform(feature_matrix)\n",
    "        \n",
    "        return self.feature_matrix\n",
    "    \n",
    "    def find_lookalikes(self, customer_id, n_recommendations=3):\n",
    "        \"\"\"Find top n similar customers for a given customer ID\"\"\"\n",
    "        # Get customer index\n",
    "        customer_idx = np.where(self.customer_ids == customer_id)[0][0]\n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        similarity_scores = cosine_similarity(\n",
    "            self.feature_matrix[customer_idx].reshape(1, -1),\n",
    "            self.feature_matrix\n",
    "        )[0]\n",
    "        \n",
    "        # Get top similar customers (excluding the customer itself)\n",
    "        similar_indices = np.argsort(similarity_scores)[::-1][1:n_recommendations+1]\n",
    "        \n",
    "        # Create recommendations list\n",
    "        recommendations = [\n",
    "            (self.customer_ids[idx], similarity_scores[idx])\n",
    "            for idx in similar_indices\n",
    "        ]\n",
    "        \n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a972a22-6a24-4029-bd15-df9b7605d8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.05188436, -0.05478053, ...,  0.24704743,\n",
       "        -0.46291005,  0.21161827],\n",
       "       [-0.45129368, -0.86271433, -0.9039848 , ...,  0.24704743,\n",
       "        -0.46291005, -0.53090197],\n",
       "       [-0.45129368, -0.393842  , -0.01157526, ...,  0.24704743,\n",
       "         0.3086067 , -1.27342221],\n",
       "       ...,\n",
       "       [-1.35388105, -1.36869358, -0.90303305, ..., -0.53723012,\n",
       "        -1.2344268 , -0.53090197],\n",
       "       [-0.45129368, -0.79937112, -0.78342303, ...,  0.24704743,\n",
       "        -0.46291005, -0.53090197],\n",
       "       [ 0.        ,  0.71127787,  1.1072471 , ..., -0.53723012,\n",
       "         0.3086067 ,  0.21161827]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train model\n",
    "model = CustomerLookalikeModel()\n",
    "model.load_data()\n",
    "model.create_customer_features()\n",
    "model.prepare_feature_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc980af-4c59-481d-8844-4ee0fe73dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations for first 20 customers\n",
    "results = []\n",
    "first_20_customers = model.customers_df['CustomerID'].iloc[:20]\n",
    "\n",
    "for customer_id in first_20_customers:\n",
    "    lookalikes = model.find_lookalikes(customer_id)\n",
    "    \n",
    "    # Format results\n",
    "    results.append({\n",
    "        'customer_id': customer_id,\n",
    "        'lookalike_1': lookalikes[0][0],\n",
    "        'score_1': round(lookalikes[0][1], 4),\n",
    "        'lookalike_2': lookalikes[1][0],\n",
    "        'score_2': round(lookalikes[1][1], 4),\n",
    "        'lookalike_3': lookalikes[2][0],\n",
    "        'score_3': round(lookalikes[2][1], 4)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b5751ef-39d1-4ea1-aaac-316512c7f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save Lookalike.csv\n",
    "lookalike_df = pd.DataFrame(results)\n",
    "lookalike_df.to_csv('Dasappagari_Sreenivas_Lookalike.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6e4e5-4618-4370-ba8e-8cbcd5986707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
